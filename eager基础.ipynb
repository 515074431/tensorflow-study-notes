{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"eager基础.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ib0YiP9xP1IU","colab_type":"text"},"source":["#eager执行基础\n","\n","这是使用TensorFlow的入门教程。它将涵盖：\n","\n","- 导入所需的包\n","- 创建和使用张量\n","- 使用GPU加速\n","- 数据集\n","\n","##导入TensorFlow\n","首先，导入tensorflow模块并启用急切执行。渴望执行可以为TensorFlow提供更具交互性的前端，我们将在稍后讨论其详细信息。"]},{"cell_type":"code","metadata":{"id":"LW4PZNXtO7N3","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import, division, print_function\n","\n","import tensorflow as tf\n","\n","tf.enable_eager_execution()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RL_66HixQyS5","colab_type":"text"},"source":["## 张量\n","张量是一个多维数组。与NumPy ndarray对象类似，Tensor对象具有数据类型和形状。此外，Tensors可以驻留在加速器（如GPU）内存中。TensorFlow提供了丰富的操作库（`tf.add，tf.matmul，tf.linalg.inv`等），它们使用和生成Tensors。这些操作自动转换本机Python类型。例如："]},{"cell_type":"code","metadata":{"id":"Lxuq3rcOQX95","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"outputId":"160177ba-35f3-4445-b80d-726c789b8b29","executionInfo":{"status":"ok","timestamp":1566543533892,"user_tz":-480,"elapsed":2195,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["print(tf.add(1,2))\n","print(tf.add([1,2],[3,4]))\n","print(tf.square(5))\n","print(tf.reduce_sum([1,2,3]))\n","print(tf.encode_base64(\"hello world\"))\n","\n","#Operator overloading is also supported\n","print(tf.square(2) + tf.square(3))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["tf.Tensor(3, shape=(), dtype=int32)\n","tf.Tensor([4 6], shape=(2,), dtype=int32)\n","tf.Tensor(25, shape=(), dtype=int32)\n","tf.Tensor(6, shape=(), dtype=int32)\n","tf.Tensor(b'aGVsbG8gd29ybGQ', shape=(), dtype=string)\n","tf.Tensor(13, shape=(), dtype=int32)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uafXn4djRiZg","colab_type":"text"},"source":["每个Tensor都有一个形状和一个数据类型"]},{"cell_type":"code","metadata":{"id":"2QS0t_X-RU5q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"477c97e0-f35b-4319-e0fe-2ea823cd420b","executionInfo":{"status":"ok","timestamp":1566543637650,"user_tz":-480,"elapsed":1501,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["x = tf.matmul([[1]],[[2,3]])\n","print(x.shape)\n","print(x.dtype)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["(1, 2)\n","<dtype: 'int32'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"73XrugBwRuZp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"fbe69527-d810-40f5-b701-22abe833b6ac","executionInfo":{"status":"ok","timestamp":1566543662509,"user_tz":-480,"elapsed":1901,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["x"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: id=30, shape=(1, 2), dtype=int32, numpy=array([[2, 3]], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"yP7OijTAR9ub","colab_type":"text"},"source":["NumPy阵列和TensorFlow张量之间最明显的区别是：\n","\n","1. 张量可以由加速器内存（如GPU，TPU）支持。\n","2. 张量是不可改变的。\n","\n","##NumPy兼容性\n","\n","TensorFlow张量和NumPy ndarrays之间的转换非常简单，如：\n","\n","- TensorFlow操作自动将NumPy ndarrays转换为Tensors。\n","- NumPy操作自动将Tensors转换为NumPy ndarrays。\n","\n","通过调用.numpy()它们的方法，可以将张量显式转换为NumPy ndarrays 。这些转换通常很便宜，因为如果可能，数组和Tensor共享底层内存表示。但是，共享底层表示并不总是可行的，因为Tensor可以托管在GPU内存中，而NumPy阵列总是由主机内存支持，因此转换将涉及从GPU到主机内存的复制。"]},{"cell_type":"code","metadata":{"id":"_eT35Jc2R0X7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":251},"outputId":"7169e8b4-c621-485d-fae8-8883478d56de","executionInfo":{"status":"ok","timestamp":1566544011658,"user_tz":-480,"elapsed":2262,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["import numpy as np\n","\n","ndarray = np.ones([3,3])\n","\n","print(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\n","tensor = tf.multiply(ndarray, 42)\n","print(tensor)\n","\n","print(\"And NumPy operations convert Tensors to numpy arrays automatically\")\n","print(np.add(tensor, 1))\n","\n","print(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\n","print(tensor.numpy())"],"execution_count":5,"outputs":[{"output_type":"stream","text":["TensorFlow operations convert numpy arrays to Tensors automatically\n","tf.Tensor(\n","[[42. 42. 42.]\n"," [42. 42. 42.]\n"," [42. 42. 42.]], shape=(3, 3), dtype=float64)\n","And NumPy operations convert Tensors to numpy arrays automatically\n","[[43. 43. 43.]\n"," [43. 43. 43.]\n"," [43. 43. 43.]]\n","The .numpy() method explicitly converts a Tensor to a numpy array\n","[[42. 42. 42.]\n"," [42. 42. 42.]\n"," [42. 42. 42.]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VMXKXcqNT2qn","colab_type":"text"},"source":["##GPU加速\n","通过使用GPU进行计算，可以加速许多TensorFlow操作。在没有任何注释的情况下，TensorFlow会自动决定是使用GPU还是CPU进行操作（如果需要，还可以复制CPU和GPU内存之间的张量）。由操作产生的张量通常由执行操作的设备的存储器支持。例如："]},{"cell_type":"code","metadata":{"id":"Sg3gegRNTJhw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"469bc69a-2b4f-42c3-ec1a-bcebfe6cd31f","executionInfo":{"status":"ok","timestamp":1566544360731,"user_tz":-480,"elapsed":1363,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["x = tf.random_uniform([3,3])\n","\n","print(\"Is there a GPU available: \"),\n","print(tf.test.is_gpu_available())\n","\n","print(\"Is the Tensor on GPU #0: \"),\n","print(x.device.endswith('GPU:0'))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Is there a GPU available: \n","True\n","Is the Tensor on GPU #0: \n","True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"an7c6U9pUpWC","colab_type":"text"},"source":["##设备名称\n","该Tensor.device属性提供托管张量内容的设备的完全限定字符串名称。此名称编码许多详细信息，例如正在执行此程序的主机的网络地址的标识符以及该主机中的设备。这是分布式执行TensorFlow程序所必需的。GPU:<N>如果张量位于N主机上的第-GPU上，则字符串结束。\n","\n","##显式设备放置\n","TensorFlow中的术语“放置”指的是如何为执行设备分配（放置）各个操作。如上所述，当没有提供明确的指导时，TensorFlow会自动决定执行操作的设备，并在需要时将Tensors复制到该设备。但是，可以使用tf.device上下文管理器将TensorFlow操作显式放置在特定设备上。例如："]},{"cell_type":"code","metadata":{"id":"5Wj0BpDXUe-P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"3f335963-2cbd-42b4-e8c4-e39c7a5334f4","executionInfo":{"status":"ok","timestamp":1566544853354,"user_tz":-480,"elapsed":2051,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["import time\n","\n","def time_matmul(x):\n","  start = time.time()\n","  for loop in range(10):\n","    tf.matmul(x,x)\n","    \n","  result = time.time() - start\n","  \n","  print(\"10 loops:  {:0.2f}ms\".format(1000 * result))\n","  \n","  \n","#Force execution on CPU\n","print(\"On CPU:\")\n","with tf.device(\"CPU:0\"):\n","  x = tf.random_uniform([1000,1000])\n","  assert x.device.endswith(\"CPU:0\")\n","  time_matmul(x)\n","  \n","  \n","#Force execution on GPU #0 if available\n","if tf.test.is_gpu_available():\n","  with tf.device(\"GPU:0\"):# Or GPU:1 for the 2nd GPU,GPU:2 for the 3rd etc.\n","    x = tf.random_uniform([1000,1000])\n","    assert x.device.endswith(\"GPU:0\")\n","    time_matmul(x)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["On CPU:\n","10 loops:  227.69ms\n","10 loops:  684.68ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C7v1D84QXW4g","colab_type":"text"},"source":["## 数据集\n","本节演示了使用 tf.data.Dataset用于构建管道以将数据提供给模型的API。它涵盖：\n","\n","- 创建一个Dataset。\n","- 在Dataset启用了急切执行的情况下进行迭代。\n","\n","我们建议使用Datasets API从简单，可重复使用的部分构建高性能，复杂的输入管道，这些部分将为模型的培训或评估循环提供支持。\n","\n","如果您熟悉TensorFlow图，则在Dataset启用eager执行时，构建对象的API 保持完全相同，但迭代数据集元素的过程稍微简单一些。您可以对tf.data.Dataset对象使用Python迭代，而不需要显式创建tf.data.Iterator对象。因此，在启用eager执行时，TensorFlow Guide中对迭代器的讨论无关紧要。\n","\n","#### 创建一个源 Dataset\n","使用其中一个工厂函数创建源数据集Dataset.from_tensors， Dataset.from_tensor_slices或者使用从TextLineDataset或等文件中读取的对象TFRecordDataset。有关详细信息，请参阅TensorFlow指南。"]},{"cell_type":"code","metadata":{"id":"hVDq42eKWXD6","colab_type":"code","colab":{}},"source":["ds_tensors = tf.data.Dataset.from_tensor_slices([1,2,3,4,5,6])\n","\n","#Create a CSV file\n","import tempfile\n","_, filename = tempfile.mkstemp()\n","\n","with open(filename, 'w') as f:\n","  f.write(\"\"\"Line 1\n","  Line 2\n","  Line 3\n","  \"\"\")\n","  \n","  ds_file = tf.data.TextLineDataset(filename)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E7e7CxYnYj2h","colab_type":"text"},"source":["## 应用转换\n","使用如转换功能map，batch，shuffle等来转换应用到数据集的记录。有关详细信息，请参阅API文档tf.data.Dataset。"]},{"cell_type":"code","metadata":{"id":"G6yUJMxYYY2M","colab_type":"code","colab":{}},"source":["ds_tensors = ds_tensors.map(tf.square).shuffle(2).batch(2)\n","\n","ds_file = ds_file.batch(2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mcp7nM5gai9N","colab_type":"text"},"source":["##重复\n","当启用eager执行时，Dataset对象支持迭代。如果您熟悉Dataset在TensorFlow图中使用s，请注意不需要呼叫Dataset.make_one_shot_iterator()或get_next()呼叫。"]},{"cell_type":"code","metadata":{"id":"WDipsL8mY5R0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":161},"outputId":"d1ba05d7-de8d-420b-de2b-5d6f76752595","executionInfo":{"status":"ok","timestamp":1566546037149,"user_tz":-480,"elapsed":1399,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["print(\"Elements of ds_tensors:\")\n","for x in ds_tensors:\n","  print(x)\n","  \n","print(\"\\nElements in ds_file:\")\n","for x in ds_file:\n","  print(x)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Elements of ds_tensors:\n","tf.Tensor([4 1], shape=(2,), dtype=int32)\n","tf.Tensor([ 9 16], shape=(2,), dtype=int32)\n","tf.Tensor([36 25], shape=(2,), dtype=int32)\n","\n","Elements in ds_file:\n","tf.Tensor([b'Line 1' b'  Line 2'], shape=(2,), dtype=string)\n","tf.Tensor([b'  Line 3' b'  '], shape=(2,), dtype=string)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Bc3px93a4Pi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}