{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"自动微分.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"WbkxeIe9bm8X","colab_type":"text"},"source":["## 自动微分\n","\n","在上一个教程中，我们介绍Tensor了它们的操作和操作。在本教程中，我们将介绍自动差异化，这是优化机器学习模型的关键技术。\n","\n","##建立"]},{"cell_type":"code","metadata":{"id":"4g1BLCgHbgG7","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import tensorflow as tf\n","\n","tf.enable_eager_execution()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_KdEJjEqcksg","colab_type":"text"},"source":["## Gradient tapes\n","TensorFlow提供用于自动区分的tf.GradientTape API - 计算与其输入变量相关的计算梯度。Tensorflow“记录” tf.GradientTape在“磁带” 上下文中执行的所有操作。Tensorflow然后使用该磁带和与每个记录操作相关联的梯度来计算使用反向模式区分的“记录”计算的梯度。\n","\n","例如："]},{"cell_type":"code","metadata":{"id":"FGuEaUrpcIgw","colab_type":"code","colab":{}},"source":["x = tf.ones((2,2))\n","\n","with tf.GradientTape() as t:\n","  t.watch(x)\n","  y = tf.reduce_sum(x)\n","  z = tf.multiply(y,y)\n","  \n","  \n","  \n","# Derivative of z with respect to the original input tensor x\n","dz_dx = t.gradient(z, x)\n","for i in [0,1]:\n","  for j in [0,1]:\n","    assert dz_dx[i][j].numpy() == 8.0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RTufeGGDdnSa","colab_type":"text"},"source":["您还可以根据在“记录” tf.GradientTape上下文中计算的中间值请求输出的渐变。"]},{"cell_type":"code","metadata":{"id":"Vr_9AcfldfIg","colab_type":"code","colab":{}},"source":["x = tf.ones((2,2))\n","\n","with tf.GradientTape() as t:\n","  t.watch(x)\n","  y = tf.reduce_sum(x)\n","  z = tf.multiply(y,y)\n","  \n","#Use the tape to compute the derivative of z with respect to the intermediate value y.\n","dz_dy = t.gradient(z,y)\n","assert dz_dy.numpy() == 8.0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TN2JULueeh5T","colab_type":"text"},"source":["默认情况下，GradientTape持有的资源会在调用GradientTape.gradient（）方法后立即释放。要在同一计算中计算多个渐变，请创建persistent渐变磁带。这允许多次调用该gradient()方法。当磁带对象被垃圾收集时释放资源。例如："]},{"cell_type":"code","metadata":{"id":"iuDmF4QzeU3I","colab_type":"code","colab":{}},"source":["x = tf.constant(3.0)\n","with tf.GradientTape(persistent=True) as t:\n","  t.watch(x)\n","  y = x*x\n","  z = y*y\n","  \n","dz_dx = t.gradient(z,x) # 108.0 (4*x^3 at x = 3)\n","dy_dx = t.gradient(y,x) # 6.0\n","\n","del t #Drop the reference to the tape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G-tb6OYdfXsQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"689349a3-0b7b-4a75-e620-188326b8dcae","executionInfo":{"status":"ok","timestamp":1566547223497,"user_tz":-480,"elapsed":1633,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["dz_dx"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: id=75, shape=(), dtype=float32, numpy=108.0>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"cw--fhiOfZ0v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"0cac1470-741f-4a84-e3d4-a15680a335c2","executionInfo":{"status":"ok","timestamp":1566547237939,"user_tz":-480,"elapsed":1948,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["dy_dx"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: id=79, shape=(), dtype=float32, numpy=6.0>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"ZQTrYIDKfdRf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"a42d2c55-0825-4dfb-a627-772c33e76674","executionInfo":{"status":"ok","timestamp":1566547254054,"user_tz":-480,"elapsed":2015,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["x"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: id=66, shape=(), dtype=float32, numpy=3.0>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"Uu2vigLFfhMP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"8cd95d3d-f71c-478d-d607-81c3fb43877a","executionInfo":{"status":"ok","timestamp":1566547313308,"user_tz":-480,"elapsed":1615,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["y"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: id=67, shape=(), dtype=float32, numpy=9.0>"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"PwFM1gT-fvwP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"b95d4f22-6d8f-40e8-c8c6-a437e9626fa7","executionInfo":{"status":"ok","timestamp":1566547317902,"user_tz":-480,"elapsed":1676,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["z"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: id=68, shape=(), dtype=float32, numpy=81.0>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"VFXkCKzigT88","colab_type":"text"},"source":["##记录控制流程\n","因为磁带在执行时记录操作，所以自然会处理Python控制流（例如使用ifs和whiles）："]},{"cell_type":"code","metadata":{"id":"BIktUb0gfw22","colab_type":"code","colab":{}},"source":["def f(x, y):\n","  output = 1.0\n","  for i in range(y):\n","    if i >1 and i < 5:\n","      output = tf.multiply(output,x)\n","      \n","  return output\n","\n","def grad(x,y):\n","  with tf.GradientTape() as t:\n","    t.watch(x)\n","    out = f(x,y)\n","    \n","  return t.gradient(out, x)\n","\n","x = tf.convert_to_tensor(2.0)\n","\n","assert grad(x,6).numpy() == 12.0\n","assert grad(x,5).numpy() == 12.0\n","assert grad(x,4).numpy() == 4.0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UJSenJFwhPzf","colab_type":"text"},"source":["## 高阶梯度\n","`GradientTape`记录上下文管理器内部的操作以自动区分。如果在该上下文中计算梯度，则也记录梯度计算。因此，完全相同的API也适用于高阶梯度。例如："]},{"cell_type":"code","metadata":{"id":"-SmgxFgphHzf","colab_type":"code","colab":{}},"source":["x = tf.Variable(1.0) #Create a TensorFlow variable initialized to 1.0\n","\n","with tf.GradientTape() as t:\n","  with tf.GradientTape() as t2:\n","    y = x * x * x\n","    \n","  #Compute the gradient inside the 't' context manager\n","  #which means the gradient computation is differentiable as well.\n","  dy_dx = t2.gradient(y,x)\n","  \n","d2y_dx2 = t.gradient(dy_dx,x)\n","\n","assert dy_dx.numpy() == 3.0\n","assert d2y_dx2.numpy() == 6.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PAObY2SAiRYO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}