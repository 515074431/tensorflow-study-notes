{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Core 演示\n",
    "您可以将 TensorFlow Core 程序看作由两个互相独立的部分组成：\n",
    "\n",
    "1. 构建计算图 (`tf.Graph`)。\n",
    "2. 运行计算图（`使用 tf.Session`）。\n",
    "\n",
    "## 图\n",
    "**计算图**是排列成一个图的一系列 TensorFlow 指令。图由两种类型的对象组成。\n",
    "\n",
    "- 操作（简称“op”）：图的节点。操作描述了消耗和生成张量的计算。\n",
    "- 张量：图的边。它们代表将流经图的值。大多数 TensorFlow 函数会返回 `tf.Tensors`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 重要提示：tf.Tensors 不具有值，它们只是计算图中元素的手柄。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来构建一个简单的计算图。最基本的指令是一个常量。构建指令的 Python 函数将一个张量值作为输入值。生成的指令不需要输入值。它在运行时输出的是被传递给构造函数的值。我们可以创建如下所示的两个浮点数常量 `a` 和 `b`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(3.0,dtype=tf.float32)\n",
    "b = tf.constant(4.0) # also tf.tfloat32 implicitly\n",
    "total = a + b\n",
    "print(a)\n",
    "print(b)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，打印张量并不会如您可能预期的那样输出值 3.0、4.0 和 7.0。上述语句只会构建计算图。这些 `tf.Tensor` 对象仅代表将要运行的操作的结果。\n",
    "\n",
    "图中的每个指令都拥有唯一的名称。这个名称不同于使用 Python 分配给相应对象的名称。张量是根据生成它们的指令命名的，后面跟着输出索引，如上文的 \"add:0\" 所示。\n",
    "\n",
    "##### TensorBoard\n",
    "TensorFlow 提供了一个名为 TensorBoard 的实用程序。TensorBoard 的诸多功能之一是将计算图可视化。您只需要使用几个简单的命令就能轻松完成此操作。\n",
    "\n",
    "首先将计算图保存为 TensorBoard 摘要文件，具体操作如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('.')\n",
    "writer.add_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这将在当前目录中生成一个 event 文件，其名称格式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> events.out.tfevents.{timestamp}.{hostname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，在新的终端中使用以下 shell 命令启动 TensorBoard："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，在您的浏览器中打开 TensorBoard 的[图页面](http://localhost:6006/#graphs)，您应该会看到与以下图形类似的图：\n",
    "\n",
    "![TensorBoard screenshot](https://tensorflow.google.cn/images/getting_started_add.png)\n",
    "\n",
    "要详细了解 TensorBoard 的计算图可视化工具，请参阅 [TensorBoard：图的直观展示](https://tensorflow.google.cn/guide/graph_viz)。\n",
    "\n",
    "### 会话 (Session)\n",
    "要评估张量，需要实例化一个 `tf.Session` 对象（非正式名称为会话）。会话会封装 TensorFlow 运行时的状态，并运行 TensorFlow 操作。如果说 `tf.Graph` 像一个 `.py` 文件，那么` tf.Session` 就像一个 python 可执行对象。\n",
    "\n",
    "下面的代码会创建一个 `tf.Session` 对象，然后调用其 `run` 方法来评估我们在上文中创建的 `total` 张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当您使用 `Session.run` 请求输出节点时，TensorFlow 会回溯整个图，并流经提供了所请求的输出节点对应的输入值的所有节点。因此此指令会打印预期的值 7.0：\n",
    "\n",
    "---\n",
    "您可以将多个张量传递给 `tf.Session.run`。run 方法以透明方式处理元组或字典的任何组合，如下例所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ab': (3.0, 4.0), 'total': 7.0}\n"
     ]
    }
   ],
   "source": [
    "print(sess.run({'ab':(a,b),'total':total}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在调用 `tf.Session.run` 期间，任何 `tf.Tensor` 都只有单个值。例如，以下代码调用 `tf.random_uniform` 来生成一个 `tf.Tensor`，后者会生成随机的三元素矢量（值位于 `[0,1)` 区间内）："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vec = tf.random_uniform(shape=(3,))\n",
    "out1 = vec + 1\n",
    "out2 = vec + 2\n",
    "print(sess.run(vec))\n",
    "print(sess.run(vec))\n",
    "print(sess.run((out1,out2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "部分 TensorFlow 函数会返回 `tf.Operations`，而不是 `tf.Tensors`。对指令调用 `run` 的结果是 None。您运行指令是为了产生副作用，而不是为了检索一个值。这方面的例子包括稍后将演示的初始化和训练操作。\n",
    "\n",
    "### 供给\n",
    "目前来讲，这个图不是特别有趣，因为它总是生成一个常量结果。图可以参数化以便接受外部输入，也称为**占位符**。**占位符**表示承诺在稍后提供值，它就像函数参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面三行有点像函数。我们定义了这个函数的两个输入参数（`x` 和 `y`），然后对它们运行指令。我们可以使用 `run` 方法的 `feed_dict` 参数为占位符提供具体的值，从而评估这个具有多个输入的图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(z,feed_dict={x:3,y:4.5}))\n",
    "print(sess.run(z,feed_dict={x:[1,3],y:[2,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另请注意，`feed_dict `参数可用于覆盖图中的任何张量。占位符和其他 `tf.Tensors` 的唯一不同之处在于如果没有为占位符提供值，那么占位符会抛出错误。\n",
    "\n",
    "##### 数据集\n",
    "占位符适用于简单的实验，而数据集是将数据流式传输到模型的首选方法。\n",
    "\n",
    "要从数据集中获取可运行的 `tf.Tensor`，您必须先将其转换成 `tf.data.Iterator`，然后调用迭代器的 `get_next` 方法。\n",
    "\n",
    "创建迭代器的最简单的方式是采用 `make_one_shot_iterator` 方法。例如，在下面的代码中，`next_item` 张量将在每次` run `调用时从 `my_data` 阵列返回一行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = [\n",
    "    [0,1,],\n",
    "    [2,3,],\n",
    "    [4,5,],\n",
    "    [6,7,],\n",
    "]\n",
    "slices = tf.data.Dataset.from_tensor_slices(my_data)\n",
    "next_item = slices.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到达数据流末端时，`Dataset` 会抛出 `OutOfRangeError`。例如，下面的代码会一直读取 `next_item`，直到没有数据可读："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[2 3]\n",
      "[4 5]\n",
      "[6 7]\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        print(sess.run(next_item))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果 `Dataset` 依赖于有状态操作，则可能需要在使用迭代器之前先初始化它，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/david/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "[-1.8434087   0.89862436  1.1357645 ]\n",
      "[ 1.212826  -1.2650346  0.7153773]\n",
      "[-1.0413038   0.61553216  0.9074352 ]\n",
      "[ 1.0120066  -0.45820898 -1.1444399 ]\n",
      "[-2.242673    0.20222595  0.4572896 ]\n",
      "[ 2.0814033 -1.1940039 -0.5293054]\n",
      "[ 0.53685915 -0.74091554 -0.09156901]\n",
      "[-0.96872234  1.5659599   0.8965701 ]\n",
      "[-0.05256422  0.494796    1.1098069 ]\n",
      "[-0.9037321  2.012012  -1.6519645]\n"
     ]
    }
   ],
   "source": [
    "r = tf.random_normal([10,3])\n",
    "dataset = tf.data.Dataset.from_tensor_slices(r)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_row = iterator.get_next()\n",
    "\n",
    "sess.run(iterator.initializer)\n",
    "while True:\n",
    "    try:\n",
    "        print(sess.run(next_row))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 层\n",
    "可训练的模型必须修改图中的值，以便在输入相同值的情况下获得新的输出值。将可训练参数添加到图中的首选方法是**层**。\n",
    "\n",
    "层将变量和作用于它们的操作打包在一起。例如，**密集连接层**会对每个输出对应的所有输入执行加权和，并应用**激活函数**（可选）。连接权重和偏差由层对象管理。\n",
    "\n",
    "### 创建层\n",
    "下面的代码会创建一个 `Dense` 层，该层会接受一批输入矢量，并为每个矢量生成一个输出值。要将层应用于输入值，请将该层当做函数来调用。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,3])\n",
    "linear_model = tf.layers.Dense(units=1)\n",
    "y = linear_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "层会检查其输入数据，以确定其内部变量的大小。因此，我们必须在这里设置` x` 占位符的形状，以便层构建正确大小的权重矩阵。\n",
    "\n",
    "我们现在已经定义了输出值 `y `的计算，在我们运行计算之前，还需要处理一个细节。\n",
    "\n",
    "### 初始化层\n",
    "层包含的变量必须先**初始化**，然后才能使用。尽管可以单独初始化各个变量，但也可以轻松地初始化一个 TensorFlow 图中的所有变量（如下所示）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">重要提示：调用 `tf.global_variables_initializer` 仅会创建并返回 TensorFlow 操作的句柄。当我们使用 tf.Session.run 运行该操作时，该操作将初始化所有全局变量。\n",
    "\n",
    "另请注意，此 `global_variables_initializer` 仅会初始化创建初始化程序时图中就存在的变量。因此您应该在构建图表的最后一步添加初始化程序。\n",
    "\n",
    "### 执行层\n",
    "我们现在已经完成了层的初始化，可以像处理任何其他张量一样评估 `linear_model` 的输出张量了。例如，下面的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2344091]\n",
      " [-2.4412575]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(y,{x:[[1,2,3],[4,5,6]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 层函数的快捷方式\n",
    "对于每个层类（如 `tf.layers.Dense`)，TensorFlow 还提供了一个快捷函数（如 `tf.layers.dense`）。两者唯一的区别是快捷函数版本是在单次调用中创建和运行层。例如，以下代码等同于较早的版本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-ce3d274eb96a>:2: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "[[-1.3901321]\n",
      " [-3.566707 ]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,3])\n",
    "y = tf.layers.dense(x,units=1)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(y,{x:[[1,2,3],[4,5,6]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尽管这种方法很方便，但无法访问 `tf.layers.Layer` 对象。这会让自省和调试变得更加困难，并且无法重复使用相应的层。\n",
    "\n",
    "## 特征列\n",
    "使用特征列进行实验的最简单方法是使用`tf.feature_column.input_layer` 函数。此函数只接受密集列作为输入，因此要查看类别列的结果，您必须将其封装在 `tf.feature_column.indicator_column` 中。例如："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features = {\n",
    "    'sales': [[5],[10],[8],[9]],\n",
    "    'department':['sports','sports','gardening','gardening']\n",
    "}\n",
    "\n",
    "department_column = tf.feature_column.categorical_column_with_vocabulary_list('department',['sports','gardening'])\n",
    "department_column = tf.feature_column.indicator_column(department_column)\n",
    "\n",
    "columns = [\n",
    "    tf.feature_column.numeric_column('sales'),\n",
    "    department_column\n",
    "]\n",
    "\n",
    "inputs = tf.feature_column.input_layer(features,columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行 `inputs` 张量会将 `features` 解析为一批向量。\n",
    "\n",
    "特征列和层一样具有内部状态，因此通常需要将它们初始化。类别列会在内部使用对照表，而这些表需要单独的初始化操作 `tf.tables_initializer`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_init = tf.global_variables_initializer()\n",
    "table_init = tf.tables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run((var_init,table_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化内部状态后，您可以运行 `inputs`（像运行任何其他 `tf.Tensor` 一样）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  5.]\n",
      " [ 1.  0. 10.]\n",
      " [ 0.  1.  8.]\n",
      " [ 0.  1.  9.]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这显示了特征列如何打包输入矢量，并将独热“department”作为第一和第二个索引，将“sales”作为第三个索引。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练\n",
    "您现在已经了解 TensorFlow 核心部分的基础知识了，我们来手动训练一个小型回归模型吧。\n",
    "\n",
    "### 定义数据\n",
    "我们首先来定义一些输入值 `x`，以及每个输入值的预期输出值 `y_true`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[1],[2],[3],[4]],dtype=tf.float32)\n",
    "y_true = tf.constant([[0],[-1],[-2],[-3]],dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型\n",
    "接下来，建立一个简单的线性模型，其输出值只有 1 个："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = tf.layers.Dense(units=1)\n",
    "y_pred = linear_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您可以如下评估预测值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.31668794]\n",
      " [0.6333759 ]\n",
      " [0.9500638 ]\n",
      " [1.2667518 ]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失\n",
    "要优化模型，您首先需要定义损失。我们将使用均方误差，这是回归问题的标准损失。\n",
    "\n",
    "虽然您可以使用较低级别的数学运算手动定义，但 `tf.losses` 模块提供了一系列常用的损失函数。您可以使用它来计算均方误差，具体操作如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.419064\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.mean_squared_error(labels=y_true,predictions=y_pred)\n",
    "print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练\n",
    "TensorFlow 提供了执行标准优化算法的**优化器**。这些优化器被实现为 `tf.train.Optimizer` 的子类。它们会逐渐改变每个变量，以便将损失最小化。最简单的优化算法是**梯度下降法**，由 `tf.train.GradientDescentOptimizer` 实现。它会根据损失相对于变量的导数大小来修改各个变量。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该代码构建了优化所需的所有图组件，并返回一个训练指令。该训练指令在运行时会更新图中的变量。您可以按以下方式运行该指令："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.419064\n",
      "5.232349\n",
      "3.7145288\n",
      "2.660844\n",
      "1.9292157\n",
      "1.4210584\n",
      "1.0679662\n",
      "0.822473\n",
      "0.6516439\n",
      "0.53262496\n",
      "0.44955933\n",
      "0.39144355\n",
      "0.35064298\n",
      "0.3218598\n",
      "0.301418\n",
      "0.28676707\n",
      "0.27613696\n",
      "0.26829973\n",
      "0.26240304\n",
      "0.25785565\n",
      "0.25424728\n",
      "0.25129315\n",
      "0.24879566\n",
      "0.24661769\n",
      "0.2446641\n",
      "0.24286892\n",
      "0.24118616\n",
      "0.23958407\n",
      "0.23804057\n",
      "0.23654032\n",
      "0.2350726\n",
      "0.23363005\n",
      "0.23220742\n",
      "0.23080128\n",
      "0.22940895\n",
      "0.22802877\n",
      "0.22665943\n",
      "0.22530013\n",
      "0.2239502\n",
      "0.22260925\n",
      "0.22127694\n",
      "0.21995299\n",
      "0.21863729\n",
      "0.21732965\n",
      "0.2160299\n",
      "0.21473812\n",
      "0.21345407\n",
      "0.2121777\n",
      "0.21090908\n",
      "0.20964801\n",
      "0.20839459\n",
      "0.20714858\n",
      "0.20591007\n",
      "0.20467892\n",
      "0.20345521\n",
      "0.20223877\n",
      "0.2010296\n",
      "0.19982764\n",
      "0.19863293\n",
      "0.1974453\n",
      "0.19626485\n",
      "0.19509143\n",
      "0.19392501\n",
      "0.19276549\n",
      "0.19161299\n",
      "0.19046739\n",
      "0.1893286\n",
      "0.18819663\n",
      "0.18707143\n",
      "0.18595296\n",
      "0.18484119\n",
      "0.18373606\n",
      "0.18263756\n",
      "0.18154556\n",
      "0.18046014\n",
      "0.1793812\n",
      "0.17830867\n",
      "0.1772426\n",
      "0.1761829\n",
      "0.17512956\n",
      "0.17408249\n",
      "0.17304167\n",
      "0.1720071\n",
      "0.17097865\n",
      "0.16995642\n",
      "0.16894025\n",
      "0.16793022\n",
      "0.16692618\n",
      "0.16592817\n",
      "0.1649361\n",
      "0.16394995\n",
      "0.16296974\n",
      "0.16199534\n",
      "0.16102684\n",
      "0.16006407\n",
      "0.15910706\n",
      "0.15815581\n",
      "0.15721022\n",
      "0.15627028\n",
      "0.15533596\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    _, loss_value = sess.run((train,loss))\n",
    "    print(loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于 `train` 是一个指令而不是张量，因此它在运行时不会返回一个值。为了查看训练期间损失的进展，我们会同时运行损失张量，生成如下所示的输出值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
