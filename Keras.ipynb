{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建简单的模型\n",
    "## 序列模型\n",
    "在 Keras 中，您可以通过组合层来构建模型。模型（通常）是由层构成的图。最常见的模型类型是层的堆叠：`tf.keras.Sequential` 模型。\n",
    "\n",
    "要构建一个简单的全连接网络（即多层感知器），请运行以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Adds a densely-connected alyer with 64 units to the model:\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "# Add another:\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 配置层\n",
    "我们可以使用很多 tf.keras.layers，它们具有一些相同的构造函数参数：\n",
    "\n",
    "* `activation`：设置层的激活函数。此参数由内置函数的名称指定，或指定为可调用对象。默认情况下，系统不会应用任何激活函数。\n",
    "* `kernel_initializer` 和 `bias_initializer`：创建层权重（核和偏差）的初始化方案。此参数是一个名称或可调用对象，默认为 \"Glorot uniform\" 初始化器。\n",
    "* `kernel_regularizer` 和 `bias_regularizer`：应用层权重（核和偏差）的正则化方案，例如 L1 或 L2 正则化。默认情况下，系统不会应用正则化函数。\n",
    "\n",
    "以下代码使用构造函数参数实例化 `tf.keras.layers. Dense` 层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x1b4f6340908>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sigmoid layer:\n",
    "layers.Dense(64,activation='sigmoid')\n",
    "# Or:\n",
    "layers.Dense(64,activation=tf.sigmoid)\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernelmatrix:\n",
    "layers.Dense(64,kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# A linear layer with L2 regulariztion of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64,bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "layers.Dense(64,kernel_initializer='orthogonal')\n",
    "\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "layers.Dense(64,bias_initializer=tf.keras.initializers.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练和评估\n",
    "## 设置训练流程\n",
    "构建好模型后，通过调用 `compile` 方法配置该模型的学习流程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Adds  a densely-connected alyer with 64 units to the model:\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    # Add another:\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    # Add a softmax layer with 10 output units:\n",
    "    layers.Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras.Model.compile` 采用三个重要参数：\n",
    "\n",
    "* `optimizer`：此对象会指定训练过程。从 `tf.train` 模块向其传递优化器实例，例如 `tf.train.AdamOptimizer`、`tf.train.RMSPropOptimizer` 或 `tf.train.GradientDescentOptimizer`。\n",
    "* `loss`：要在优化期间最小化的函数。常见选择包括均方误差 (mse)、`categorical_crossentropy` 和 `binary_crossentropy`。损失函数由名称或通过从 `tf.keras.losses` 模块传递可调用对象来指定。\n",
    "* `metrics`：用于监控训练。它们是 `tf.keras.metrics` 模块中的字符串名称或可调用对象。\n",
    "\n",
    "以下代码展示了配置模型以进行训练的几个示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a model for mean-squared error regression.\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "             loss='mse', # mean squared error\n",
    "             metrics=['mae']) # mean absolute error\n",
    "\n",
    "# Configure a model for categorical classification\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输入 NumPy 数据\n",
    "对于小型数据集，请使用内存中的 **NumPy**数组训练和评估模型。使用 `fit` 方法使模型与训练数据“拟合”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 179us/sample - loss: 11.5973 - categorical_accuracy: 0.0910\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 11.5545 - categorical_accuracy: 0.0970\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 11.5404 - categorical_accuracy: 0.0970\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 11.5349 - categorical_accuracy: 0.1140\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 27us/sample - loss: 11.5343 - categorical_accuracy: 0.1200\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 27us/sample - loss: 11.5306 - categorical_accuracy: 0.1050\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 27us/sample - loss: 11.5268 - categorical_accuracy: 0.1480\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 27us/sample - loss: 11.5293 - categorical_accuracy: 0.1020\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 24us/sample - loss: 11.5241 - categorical_accuracy: 0.1280\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 11.5183 - categorical_accuracy: 0.1330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b4f7b4f8d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000,32))\n",
    "labels = np.random.random((1000,10))\n",
    "\n",
    "model.fit(data,labels,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras.Model.fit` 采用三个重要参数：\n",
    "\n",
    "- `epochs`：以周期为单位进行训练。一个周期是对整个输入数据的一次迭代（以较小的批次完成迭代）。\n",
    "- `batch_size`：当传递 NumPy 数据时，模型将数据分成较小的批次，并在训练期间迭代这些批次。此整数指定每个批次的大小。请注意，如果样本总数不能被批次大小整除，则最后一个批次可能更小。\n",
    "- `validation_data`：在对模型进行原型设计时，您需要轻松监控该模型在某些验证数据上达到的效果。传递此参数（输入和标签元组）可以让该模型在每个周期结束时以推理模式显示所传递数据的损失和指标。\n",
    "下面是使用 `validation_data` 的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 76us/sample - loss: 11.5073 - categorical_accuracy: 0.1110 - val_loss: 11.6678 - val_categorical_accuracy: 0.1200\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 11.5025 - categorical_accuracy: 0.1110 - val_loss: 11.6724 - val_categorical_accuracy: 0.0900\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 11.5018 - categorical_accuracy: 0.1230 - val_loss: 11.6722 - val_categorical_accuracy: 0.0600\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 11.4989 - categorical_accuracy: 0.1170 - val_loss: 11.6749 - val_categorical_accuracy: 0.1300\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 11.4983 - categorical_accuracy: 0.1460 - val_loss: 11.6924 - val_categorical_accuracy: 0.0600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 11.4959 - categorical_accuracy: 0.1180 - val_loss: 11.6854 - val_categorical_accuracy: 0.1200\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 11.4950 - categorical_accuracy: 0.1260 - val_loss: 11.6798 - val_categorical_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 11.4894 - categorical_accuracy: 0.1470 - val_loss: 11.6815 - val_categorical_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 11.4867 - categorical_accuracy: 0.1480 - val_loss: 11.7252 - val_categorical_accuracy: 0.0900\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 11.4840 - categorical_accuracy: 0.1490 - val_loss: 11.6844 - val_categorical_accuracy: 0.1100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b4f900cc50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "data = np.random.random((1000,32))\n",
    "labels = np.random.random((1000,10))\n",
    "\n",
    "val_data = np.random.random((100,32))\n",
    "val_labels = np.random.random((100,10))\n",
    "\n",
    "model.fit(data,labels,epochs=10,batch_size=32,\n",
    "         validation_data=(val_data,val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输入 tf.data 数据集\n",
    "使用 Datasets API 可扩展为大型数据集或多设备训练。将 `tf.data.Dataset` 实例传递到 `fit` 方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.4902 - categorical_accuracy: 0.1583\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4785 - categorical_accuracy: 0.1635\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 1000us/step - loss: 11.4506 - categorical_accuracy: 0.1560\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4685 - categorical_accuracy: 0.1549\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 967us/step - loss: 11.4747 - categorical_accuracy: 0.1624\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 967us/step - loss: 11.4391 - categorical_accuracy: 0.1709\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 933us/step - loss: 11.4290 - categorical_accuracy: 0.1667\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 933us/step - loss: 11.4215 - categorical_accuracy: 0.1709\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 967us/step - loss: 11.4201 - categorical_accuracy: 0.1838\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 900us/step - loss: 11.4376 - categorical_accuracy: 0.1912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b4f9117630>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiates a toy dataset instance:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data,labels))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "#Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\n",
    "model.fit(dataset,epochs=10,steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上方代码中，fit 方法使用了 `steps_per_epoch` 参数（表示模型在进入下一个周期之前运行的训练步数）。由于 `Dataset` 会生成批次数据，因此该代码段不需要 `batch_size`。\n",
    "\n",
    "数据集也可用于验证："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 11.4409 - categorical_accuracy: 0.1885 - val_loss: 11.7262 - val_categorical_accuracy: 0.1146\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4232 - categorical_accuracy: 0.1923 - val_loss: 11.9538 - val_categorical_accuracy: 0.0735\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.3964 - categorical_accuracy: 0.2019 - val_loss: 12.0128 - val_categorical_accuracy: 0.0441\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4138 - categorical_accuracy: 0.2094 - val_loss: 12.1574 - val_categorical_accuracy: 0.0735\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4239 - categorical_accuracy: 0.2030 - val_loss: 11.7291 - val_categorical_accuracy: 0.1146\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 1000us/step - loss: 11.3931 - categorical_accuracy: 0.2094 - val_loss: 11.9984 - val_categorical_accuracy: 0.0735\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.3825 - categorical_accuracy: 0.2062 - val_loss: 12.0275 - val_categorical_accuracy: 0.0588\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.3844 - categorical_accuracy: 0.2126 - val_loss: 12.2418 - val_categorical_accuracy: 0.0882\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 1000us/step - loss: 11.3798 - categorical_accuracy: 0.2158 - val_loss: 11.7680 - val_categorical_accuracy: 0.1458\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4033 - categorical_accuracy: 0.2201 - val_loss: 12.0915 - val_categorical_accuracy: 0.1176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b4f92a4fd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32).repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32).repeat()\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估和预测\n",
    "`tf.keras.Model.evaluate` 和 `tf.keras.Model.predict` 方法可以使用 **NumPy** 数据和 `tf.data.Dataset`。\n",
    "\n",
    "要评估所提供数据的推理模式损失和指标，请运行以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 60us/sample - loss: 11.7701 - categorical_accuracy: 0.1100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4453 - categorical_accuracy: 0.1906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.445285511016845, 0.190625]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.random((1000,32))\n",
    "labels = np.random.random((1000,10))\n",
    "\n",
    "model.evaluate(data,labels,batch_size=32)\n",
    "\n",
    "model.evaluate(dataset, steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要在所提供数据（采用 NumPy 数组形式）的推理中预测最后一层的输出，请运行以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(data,batch_size=32)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
