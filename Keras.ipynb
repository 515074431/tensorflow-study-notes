{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建简单的模型\n",
    "## 序列模型\n",
    "在 Keras 中，您可以通过组合层来构建模型。模型（通常）是由层构成的图。最常见的模型类型是层的堆叠：`tf.keras.Sequential` 模型。\n",
    "\n",
    "要构建一个简单的全连接网络（即多层感知器），请运行以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Adds a densely-connected alyer with 64 units to the model:\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "# Add another:\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 配置层\n",
    "我们可以使用很多 tf.keras.layers，它们具有一些相同的构造函数参数：\n",
    "\n",
    "* `activation`：设置层的激活函数。此参数由内置函数的名称指定，或指定为可调用对象。默认情况下，系统不会应用任何激活函数。\n",
    "* `kernel_initializer` 和 `bias_initializer`：创建层权重（核和偏差）的初始化方案。此参数是一个名称或可调用对象，默认为 \"Glorot uniform\" 初始化器。\n",
    "* `kernel_regularizer` 和 `bias_regularizer`：应用层权重（核和偏差）的正则化方案，例如 L1 或 L2 正则化。默认情况下，系统不会应用正则化函数。\n",
    "\n",
    "以下代码使用构造函数参数实例化 `tf.keras.layers. Dense` 层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x219925dc780>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sigmoid layer:\n",
    "layers.Dense(64,activation='sigmoid')\n",
    "# Or:\n",
    "layers.Dense(64,activation=tf.sigmoid)\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernelmatrix:\n",
    "layers.Dense(64,kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# A linear layer with L2 regulariztion of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64,bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "layers.Dense(64,kernel_initializer='orthogonal')\n",
    "\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "layers.Dense(64,bias_initializer=tf.keras.initializers.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练和评估\n",
    "## 设置训练流程\n",
    "构建好模型后，通过调用 `compile` 方法配置该模型的学习流程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Adds  a densely-connected alyer with 64 units to the model:\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    # Add another:\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    # Add a softmax layer with 10 output units:\n",
    "    layers.Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras.Model.compile` 采用三个重要参数：\n",
    "\n",
    "* `optimizer`：此对象会指定训练过程。从 `tf.train` 模块向其传递优化器实例，例如 `tf.train.AdamOptimizer`、`tf.train.RMSPropOptimizer` 或 `tf.train.GradientDescentOptimizer`。\n",
    "* `loss`：要在优化期间最小化的函数。常见选择包括均方误差 (mse)、`categorical_crossentropy` 和 `binary_crossentropy`。损失函数由名称或通过从 `tf.keras.losses` 模块传递可调用对象来指定。\n",
    "* `metrics`：用于监控训练。它们是 `tf.keras.metrics` 模块中的字符串名称或可调用对象。\n",
    "\n",
    "以下代码展示了配置模型以进行训练的几个示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a model for mean-squared error regression.\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "             loss='mse', # mean squared error\n",
    "             metrics=['mae']) # mean absolute error\n",
    "\n",
    "# Configure a model for categorical classification\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输入 NumPy 数据\n",
    "对于小型数据集，请使用内存中的 **NumPy**数组训练和评估模型。使用 `fit` 方法使模型与训练数据“拟合”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 200us/sample - loss: 11.5988 - categorical_accuracy: 0.0980\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 11.5448 - categorical_accuracy: 0.1080\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 11.5323 - categorical_accuracy: 0.1150\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 11.5203 - categorical_accuracy: 0.1060\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 11.5198 - categorical_accuracy: 0.1090\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 11.5148 - categorical_accuracy: 0.1180\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 11.5130 - categorical_accuracy: 0.1020\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 11.5127 - categorical_accuracy: 0.1150\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 11.5103 - categorical_accuracy: 0.1130\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 11.5051 - categorical_accuracy: 0.1420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21992708908>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000,32))\n",
    "labels = np.random.random((1000,10))\n",
    "\n",
    "model.fit(data,labels,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras.Model.fit` 采用三个重要参数：\n",
    "\n",
    "- `epochs`：以周期为单位进行训练。一个周期是对整个输入数据的一次迭代（以较小的批次完成迭代）。\n",
    "- `batch_size`：当传递 NumPy 数据时，模型将数据分成较小的批次，并在训练期间迭代这些批次。此整数指定每个批次的大小。请注意，如果样本总数不能被批次大小整除，则最后一个批次可能更小。\n",
    "- `validation_data`：在对模型进行原型设计时，您需要轻松监控该模型在某些验证数据上达到的效果。传递此参数（输入和标签元组）可以让该模型在每个周期结束时以推理模式显示所传递数据的损失和指标。\n",
    "下面是使用 `validation_data` 的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 11.6305 - categorical_accuracy: 0.1110 - val_loss: 11.7139 - val_categorical_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 11.6247 - categorical_accuracy: 0.1010 - val_loss: 11.7162 - val_categorical_accuracy: 0.1100\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 11.6233 - categorical_accuracy: 0.1040 - val_loss: 11.7054 - val_categorical_accuracy: 0.0900\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 11.6218 - categorical_accuracy: 0.1260 - val_loss: 11.7140 - val_categorical_accuracy: 0.1400\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 11.6226 - categorical_accuracy: 0.1210 - val_loss: 11.7124 - val_categorical_accuracy: 0.1200\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 11.6209 - categorical_accuracy: 0.1100 - val_loss: 11.7229 - val_categorical_accuracy: 0.1300\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 11.6176 - categorical_accuracy: 0.1210 - val_loss: 11.7449 - val_categorical_accuracy: 0.0400\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 11.6168 - categorical_accuracy: 0.1360 - val_loss: 11.7265 - val_categorical_accuracy: 0.0900\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 11.6118 - categorical_accuracy: 0.1310 - val_loss: 11.7241 - val_categorical_accuracy: 0.1200\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 11.6084 - categorical_accuracy: 0.1360 - val_loss: 11.7289 - val_categorical_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21992b355c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "data = np.random.random((1000,32))\n",
    "labels = np.random.random((1000,10))\n",
    "\n",
    "val_data = np.random.random((100,32))\n",
    "val_labels = np.random.random((100,10))\n",
    "\n",
    "model.fit(data,labels,epochs=10,batch_size=32,\n",
    "         validation_data=(val_data,val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输入 tf.data 数据集\n",
    "使用 Datasets API 可扩展为大型数据集或多设备训练。将 `tf.data.Dataset` 实例传递到 `fit` 方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 11.5950 - categorical_accuracy: 0.1479\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.6286 - categorical_accuracy: 0.1453\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5978 - categorical_accuracy: 0.1656\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5715 - categorical_accuracy: 0.1656\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5883 - categorical_accuracy: 0.1496\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5664 - categorical_accuracy: 0.1453\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5362 - categorical_accuracy: 0.1592\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5582 - categorical_accuracy: 0.1731\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5543 - categorical_accuracy: 0.1656\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5879 - categorical_accuracy: 0.1677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21992b1a518>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiates a toy dataset instance:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data,labels))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "#Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\n",
    "model.fit(dataset,epochs=10,steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上方代码中，fit 方法使用了 `steps_per_epoch` 参数（表示模型在进入下一个周期之前运行的训练步数）。由于 `Dataset` 会生成批次数据，因此该代码段不需要 `batch_size`。\n",
    "\n",
    "数据集也可用于验证："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 11.5523 - categorical_accuracy: 0.1583 - val_loss: 11.8241 - val_categorical_accuracy: 0.1146\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5832 - categorical_accuracy: 0.1763 - val_loss: 11.7159 - val_categorical_accuracy: 0.1176\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5534 - categorical_accuracy: 0.1816 - val_loss: 11.3228 - val_categorical_accuracy: 0.1176\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5319 - categorical_accuracy: 0.1635 - val_loss: 11.4193 - val_categorical_accuracy: 0.1176\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5494 - categorical_accuracy: 0.1795 - val_loss: 11.9241 - val_categorical_accuracy: 0.0625\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5235 - categorical_accuracy: 0.1976 - val_loss: 11.7083 - val_categorical_accuracy: 0.0441\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4954 - categorical_accuracy: 0.2030 - val_loss: 11.4422 - val_categorical_accuracy: 0.0294\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5155 - categorical_accuracy: 0.1944 - val_loss: 11.5216 - val_categorical_accuracy: 0.0294\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5145 - categorical_accuracy: 0.1955 - val_loss: 11.8958 - val_categorical_accuracy: 0.1042\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5505 - categorical_accuracy: 0.1966 - val_loss: 11.7473 - val_categorical_accuracy: 0.1176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21993fe87b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32).repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32).repeat()\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估和预测\n",
    "`tf.keras.Model.evaluate` 和 `tf.keras.Model.predict` 方法可以使用 **NumPy** 数据和 `tf.data.Dataset`。\n",
    "\n",
    "要评估所提供数据的推理模式损失和指标，请运行以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 100us/sample - loss: 11.6535 - categorical_accuracy: 0.1060\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.5311 - categorical_accuracy: 0.2010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.5310528755188, 0.20104167]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.random((1000,32))\n",
    "labels = np.random.random((1000,10))\n",
    "\n",
    "model.evaluate(data,labels,batch_size=32)\n",
    "\n",
    "model.evaluate(dataset, steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要在所提供数据（采用 NumPy 数组形式）的推理中预测最后一层的输出，请运行以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(data,batch_size=32)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10712593 0.10614926 0.11914968 0.10438284 0.09777807 0.08018789\n",
      "  0.08364492 0.11341213 0.09596829 0.09220092]\n",
      " [0.05993045 0.06431799 0.11444446 0.10143398 0.08408388 0.1351158\n",
      "  0.0910539  0.13234802 0.10135642 0.11591516]\n",
      " [0.09521271 0.11232687 0.09991261 0.09509832 0.10266942 0.09157606\n",
      "  0.10383549 0.0972802  0.10034923 0.10173913]\n",
      " [0.10156393 0.09303255 0.10199981 0.09310558 0.09298146 0.08690888\n",
      "  0.10563116 0.1067415  0.1123837  0.10565142]\n",
      " [0.09313243 0.09825429 0.11126506 0.09561428 0.10602416 0.08508237\n",
      "  0.11673948 0.12671322 0.07201951 0.09515522]\n",
      " [0.09622911 0.10811144 0.1045793  0.10417874 0.10168935 0.08779634\n",
      "  0.10045061 0.0986843  0.09662527 0.10165551]\n",
      " [0.09230995 0.10833034 0.09842029 0.09985278 0.10446718 0.08733904\n",
      "  0.1088278  0.10059937 0.08843445 0.11141869]\n",
      " [0.08911548 0.09282499 0.10479552 0.08142848 0.05217983 0.10513885\n",
      "  0.11305489 0.11727671 0.10720601 0.13697924]\n",
      " [0.07613072 0.12121036 0.08221168 0.07120643 0.10866243 0.11784232\n",
      "  0.11064467 0.10015702 0.10948806 0.10244635]\n",
      " [0.10359145 0.12260818 0.09590647 0.11078689 0.09929439 0.09439226\n",
      "  0.08634451 0.08763866 0.10025583 0.09918135]]\n"
     ]
    }
   ],
   "source": [
    "print(result[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建高级模型\n",
    "### 函数式 API\n",
    "`tf.keras.Sequential` 模型是层的简单堆叠，无法表示任意模型。使用 `Keras 函数式 API` 可以构建复杂的模型拓扑，例如：\n",
    "\n",
    "- 多输入模型，\n",
    "- 多输出模型，\n",
    "- 具有共享层的模型（同一层被调用多次），\n",
    "- 具有非序列数据流的模型（例如，剩余连接）。\n",
    "\n",
    "使用函数式 API 构建的模型具有以下特征：\n",
    "\n",
    "1. 层实例可调用并返回张量。\n",
    "2. 输入张量和输出张量用于定义 `tf.keras.Model `实例。\n",
    "3. 此模型的训练方式和` Sequential `模型一样。\n",
    "以下示例使用函数式 API 构建一个简单的全连接网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(32,)) # Returns a placeholder tensor\n",
    "\n",
    "#A layer instance is callable on a tensor , and returns a tensor.\n",
    "x = layers.Dense(64,activation='relu')(inputs)\n",
    "x = layers.Dense(64,activation='relu')(x)\n",
    "predictions = layers.Dense(10,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在给定输入和输出的情况下实例化模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 196us/sample - loss: 11.7163 - acc: 0.0920\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 11.6079 - acc: 0.0850\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 11.5692 - acc: 0.0930\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 11.5568 - acc: 0.0960\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 11.5491 - acc: 0.0930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2199bebd438>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=inputs,outputs=predictions)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#Trains for 5 epochs\n",
    "model.fit(data,labels,batch_size=32,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型子类化\n",
    "通过对 `tf.keras.Model` 进行子类化并定义您自己的前向传播来构建完全可自定义的模型。在` __init__` 方法中创建层并将它们设置为类实例的属性。在 `call `方法中定义前向传播。\n",
    "\n",
    "在启用` Eager Execution` 时，模型子类化特别有用，因为可以命令式地编写前向传播。\n",
    "\n",
    ">要点：针对作业使用正确的 API。虽然模型子类化较为灵活，但代价是复杂性更高且用户出错率更高。如果可能，请首选函数式 API。\n",
    "\n",
    "以下示例展示了使用自定义前向传播进行子类化的` tf.keras.Model`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(MyModel,self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        #Define your layers here\n",
    "        self.dense_1 = layers.Dense(32,activation='relu')\n",
    "        self.dense_2 = layers.Dense(num_classes,activation='sigmoid')\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        #Define your forward pass here,\n",
    "        #using layers you previously defined (in `__init__`).\n",
    "        x = self.dense_1(inputs)\n",
    "        return self.dense_2(x)\n",
    "    \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        #You need to override this fuction if you want to use the subclassed model\n",
    "        # as part of a functional-style model.\n",
    "        # Otherwise,this method is optional\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.num_classes\n",
    "        return tf.TensorShape(shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实例化新模型类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 173us/sample - loss: 11.7401 - acc: 0.1040\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 11.6712 - acc: 0.1040\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 11.5933 - acc: 0.1070\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 11.5640 - acc: 0.1190\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 11.5568 - acc: 0.1110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2199d870c50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel(num_classes=10)\n",
    "\n",
    "#The compile step specifies the training configuration\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#Trains for 5 epochs\n",
    "model.fit(data,labels,batch_size=32,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义层\n",
    "通过对 `tf.keras.layers.Layer `进行子类化并实现以下方法来创建自定义层：\n",
    "\n",
    "- `build`：创建层的权重。使用 `add_weight` 方法添加权重。\n",
    "- `call`：定义前向传播。\n",
    "- `compute_output_shape`：指定在给定输入形状的情况下如何计算层的输出形状。\n",
    "- 或者，可以通过实现 `get_config` 方法和 `from_config` 类方法序列化层。\n",
    "下面是一个使用核矩阵实现输入 `matmul` 的自定义层示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "\n",
    "  def __init__(self, output_dim, **kwargs):\n",
    "    self.output_dim = output_dim\n",
    "    super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
    "    # Create a trainable weight variable for this layer.\n",
    "    self.kernel = self.add_weight(name='kernel',\n",
    "                                  shape=shape,\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "    # Be sure to call this at the end\n",
    "    super(MyLayer, self).build(input_shape)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "  def compute_output_shape(self, input_shape):\n",
    "    shape = tf.TensorShape(input_shape).as_list()\n",
    "    shape[-1] = self.output_dim\n",
    "    return tf.TensorShape(shape)\n",
    "\n",
    "  def get_config(self):\n",
    "    base_config = super(MyLayer, self).get_config()\n",
    "    base_config['output_dim'] = self.output_dim\n",
    "    return base_config\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(cls, config):\n",
    "    return cls(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用自定义层创建模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 172us/sample - loss: 11.5722 - acc: 0.0950\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 11.5561 - acc: 0.0940\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 11.5506 - acc: 0.0990\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 11.5487 - acc: 0.0950\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 11.5472 - acc: 0.1020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x219a11d22e8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    MyLayer(10),\n",
    "    layers.Activation('softmax')])\n",
    "\n",
    "# The compile step specifies the training configuration\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回调\n",
    "回调是传递给模型的对象，用于在训练期间自定义该模型并扩展其行为。您可以编写自定义回调，也可以使用包含以下方法的内置 `tf.keras.callbacks`：\n",
    "\n",
    "- `tf.keras.callbacks.ModelCheckpoint`：定期保存模型的检查点。\n",
    "- `tf.keras.callbacks.LearningRateScheduler`：动态更改学习速率。\n",
    "- `tf.keras.callbacks.EarlyStopping`：在验证效果不再改进时中断训练。\n",
    "- `tf.keras.callbacks.TensorBoard`：使用 `TensorBoard` 监控模型的行为。\n",
    "\n",
    "要使用 `tf.keras.callbacks.Callback`，请将其传递给模型的 `fit` 方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 11.5449 - acc: 0.1070 - val_loss: 11.7121 - val_acc: 0.1400\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 11.5436 - acc: 0.0930 - val_loss: 11.7148 - val_acc: 0.1100\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 11.5422 - acc: 0.1110 - val_loss: 11.7158 - val_acc: 0.1400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2199f2caeb8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    #Interrupt training if 'val_loss' stop improving for over 2 epochs\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2,monitor='val_loss'),\n",
    "    #Write TensorBoard logs to './logs' directory\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./TensorBoardLog/')\n",
    "]\n",
    "\n",
    "model.fit(data,labels,batch_size=32,epochs=5,callbacks=callbacks,\n",
    "         validation_data=(val_data,val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存和恢复\n",
    "##### 仅限权重\n",
    "\n",
    "使用 `tf.keras.Model.save_weights` 保存并加载模型的权重："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdadeltaOptimizer(0.001),\n",
    "             loss='categorical_crossentopy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x219a0d935f8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save weights to a TensorFlow Checkpoint file\n",
    "model.save_weights('./model/weights/my_model')\n",
    "\n",
    "#Restore the model's state,\n",
    "#this requires a model with the same architecture\n",
    "model.load_weights('./model/weights/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_6\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_20\", \"trainable\": true, \"dtype\": null, \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_21\", \"trainable\": true, \"dtype\": null, \"units\": 10, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string = model.to_json()\n",
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'backend': 'tensorflow',\n",
      " 'class_name': 'Sequential',\n",
      " 'config': {'layers': [{'class_name': 'Dense',\n",
      "                        'config': {'activation': 'relu',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {'dtype': 'float32'}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': None,\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'dtype': 'float32',\n",
      "                                                                     'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_20',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 64,\n",
      "                                   'use_bias': True}},\n",
      "                       {'class_name': 'Dense',\n",
      "                        'config': {'activation': 'softmax',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {'dtype': 'float32'}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': None,\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'dtype': 'float32',\n",
      "                                                                     'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_21',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 10,\n",
      "                                   'use_bias': True}}],\n",
      "            'name': 'sequential_6'},\n",
      " 'keras_version': '2.2.4-tf'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "pprint.pprint(json.loads(json_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
