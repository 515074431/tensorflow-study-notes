{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"自定义层.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8ufIykr_VGYZ","colab_type":"text"},"source":["#自定义图层\n","\n","我们建议将其tf.keras用作构建神经网络的高级API。也就是说，大多数TensorFlow API都可用于急切执行。"]},{"cell_type":"code","metadata":{"id":"zU6MPj02U-67","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import tensorflow as tf\n","\n","tf.enable_eager_execution()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6apkeOo2VttZ","colab_type":"text"},"source":["##图层：常用的有用操作集\n","大多数情况下，为机器学习模型编写代码时，您希望在比单个操作和单个变量操作更高的抽象级别上操作。\n","\n","许多机器学习模型都可以表达为相对简单的层的组合和堆叠，而TensorFlow提供了一组许多常用层，以及您从头开始或作为组合创建自己的应用程序特定层的简单方法。现有的图层。\n","\n","TensorFlow包括完整Keras在tf.keras封装API，并建立自己的模型时，Keras层是非常有用的。"]},{"cell_type":"code","metadata":{"id":"cIiXlxdEVhgX","colab_type":"code","colab":{}},"source":["# In the tf.keras.layers package, layers are objects. To construct a layer,\n","#simply construct the object. Most layers take as a first argument the number\n","# of output dimensions / channels.\n","layer = tf.keras.layers.Dense(100)\n","# The number of input dimensions is often unnecessary, as it can be inferred\n","# the first time the layer is used, but it can be provided if you want to \n","# specify it manually, which is useful in some complex models.\n","layer = tf.keras.layers.Dense(10, input_shape=(None, 5))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jO6In3zvXSSN","colab_type":"text"},"source":["可以在[文档中](https://https://www.tensorflow.org/api_docs/python/tf/keras/layers)看到预先存在的图层的完整列表。它包括Dense（完全连接层），Conv2D，LSTM，BatchNormalization，Dropout等等。"]},{"cell_type":"code","metadata":{"id":"QGIIrmQ0WweA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":248},"outputId":"1460871e-ebac-4ce4-a2de-ee8b3af61613","executionInfo":{"status":"ok","timestamp":1566732972912,"user_tz":-480,"elapsed":6101,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["# To use a layer, simply call it.\n","layer(tf.zeros([10,5]))"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: id=29, shape=(10, 10), dtype=float32, numpy=\n","array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"buO5F27JX-Y0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":310},"outputId":"d54908be-c234-4a30-a4e4-5068ec5a0a6c","executionInfo":{"status":"ok","timestamp":1566732972914,"user_tz":-480,"elapsed":6096,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["# Layers have many useful methods. For example, you can inspect all variables\n","# in a layer using `layer.variables` and trainable variables using\n","# `layer.trainable_variables`. In this case a fully-connected layer\n","# will have variables for weights and biases.\n","layer.variables"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n"," array([[ 0.15839541,  0.33652818,  0.05446959,  0.2981816 ,  0.34496832,\n","          0.34179062,  0.0978961 , -0.2944942 , -0.49470466,  0.58395964],\n","        [ 0.09877837, -0.5166745 , -0.22292516, -0.44088125,  0.50255007,\n","          0.06522959, -0.6230375 ,  0.56266683,  0.24604386, -0.27850106],\n","        [-0.51025283, -0.19881204, -0.0418992 ,  0.29163212, -0.11847174,\n","         -0.39820457, -0.18268648,  0.15275526,  0.07371175, -0.5352407 ],\n","        [ 0.48866326,  0.25386983,  0.0460397 , -0.5651083 , -0.3633575 ,\n","          0.13588065, -0.2829908 , -0.21680239, -0.579241  ,  0.595136  ],\n","        [-0.17696479, -0.3160016 , -0.280664  , -0.33502635,  0.03826153,\n","          0.6114345 , -0.52762026,  0.03110737, -0.49838755, -0.403283  ]],\n","       dtype=float32)>,\n"," <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"TTs6lnBtYOw4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":310},"outputId":"ec10b9e5-e6ed-4283-9839-4ae39a412329","executionInfo":{"status":"ok","timestamp":1566732972915,"user_tz":-480,"elapsed":6088,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["# The variables are also accessible through nice accessors\n","layer.kernel, layer.bias"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n"," array([[ 0.15839541,  0.33652818,  0.05446959,  0.2981816 ,  0.34496832,\n","          0.34179062,  0.0978961 , -0.2944942 , -0.49470466,  0.58395964],\n","        [ 0.09877837, -0.5166745 , -0.22292516, -0.44088125,  0.50255007,\n","          0.06522959, -0.6230375 ,  0.56266683,  0.24604386, -0.27850106],\n","        [-0.51025283, -0.19881204, -0.0418992 ,  0.29163212, -0.11847174,\n","         -0.39820457, -0.18268648,  0.15275526,  0.07371175, -0.5352407 ],\n","        [ 0.48866326,  0.25386983,  0.0460397 , -0.5651083 , -0.3633575 ,\n","          0.13588065, -0.2829908 , -0.21680239, -0.579241  ,  0.595136  ],\n","        [-0.17696479, -0.3160016 , -0.280664  , -0.33502635,  0.03826153,\n","          0.6114345 , -0.52762026,  0.03110737, -0.49838755, -0.403283  ]],\n","       dtype=float32)>,\n"," <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"XAkQAbLoYt-0","colab_type":"text"},"source":["##实现自定义图层\n","实现自己的层的最佳方法是扩展tf.keras.Layer类并实现：* __init__，您可以在其中执行所有与输入无关的初始化* build，您可以在其中了解输入张量的形状并可以执行其余的初始化* call，在哪里进行正向计算\n","\n","请注意，您不必等到build调用创建变量，您也可以在其中创建变量__init__。但是，创建它们的优点build是它可以根据图层将要操作的输入的形状启用后期变量创建。另一方面，创建变量__init__意味着需要明确指定创建变量所需的形状。"]},{"cell_type":"code","metadata":{"id":"pDkyec8rYa-L","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":689},"outputId":"459460ec-b446-4871-f251-a17e9207687c","executionInfo":{"status":"ok","timestamp":1566732972916,"user_tz":-480,"elapsed":6084,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["class MyDenseLayer(tf.keras.layers.Layer):\n","  def __init__(self, num_outputs):\n","    super(MyDenseLayer, self).__init__()\n","    self.num_outputs = num_outputs\n","    \n","  def build(self, input_shape):\n","    self.kernel = self.add_variable(\"kernel\",\n","                                   shape=[int(input_shape[-1]),\n","                                         self.num_outputs])\n","    \n","  def call(self, input):\n","    return tf.matmul(input, self.kernel)\n","  \n","layer = MyDenseLayer(10)\n","print(layer(tf.zeros([10,5])))\n","print(layer.trainable_variables)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["tf.Tensor(\n","[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n","[<tf.Variable 'my_dense_layer/kernel:0' shape=(5, 10) dtype=float32, numpy=\n","array([[ 4.95858967e-01,  2.86221325e-01, -2.06197232e-01,\n","         4.81222928e-01, -5.64075828e-01, -4.57111895e-01,\n","        -5.44994473e-02, -2.85998166e-01,  4.69181955e-01,\n","         4.96079981e-01],\n","       [ 2.38072395e-01, -5.10455012e-01, -1.04665756e-04,\n","         4.84037399e-02, -2.16632903e-01, -4.34904695e-02,\n","         3.53232324e-01,  5.11702478e-01,  5.98318040e-01,\n","        -4.22724545e-01],\n","       [-3.92193675e-01, -3.97662520e-01,  4.28095400e-01,\n","         1.44044340e-01, -2.72432566e-01,  3.95300806e-01,\n","        -4.60255682e-01, -2.47630924e-01,  2.73113966e-01,\n","         3.58848631e-01],\n","       [ 3.58415425e-01,  5.42528689e-01,  5.98560631e-01,\n","        -4.70243037e-01, -4.70938504e-01, -1.49584800e-01,\n","         3.02957714e-01, -3.41789544e-01, -5.38076460e-01,\n","        -7.95109868e-02],\n","       [ 2.47106493e-01, -5.17846406e-01,  4.60321844e-01,\n","        -1.51765645e-01, -5.15991449e-01, -1.52789831e-01,\n","         4.96631861e-02,  3.82332385e-01, -2.52642989e-01,\n","         7.67495632e-02]], dtype=float32)>]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_jCbcqW_kcZU","colab_type":"text"},"source":["如果尽可能使用标准层，则整体代码更易于阅读和维护，因为其他读者将熟悉标准层的行为。如果你想使用tf.keras.layers或tf.contrib.layers中不存在的图层，请考虑提交github问题，或者更好的是向我们发送拉取请求！\n","\n","##模型：组成图层\n","机器学习模型中许多有趣的层状事物是通过组合现有层来实现的。例如，resnet中的每个残余块是卷积，批量标准化和快捷方式的组合。\n","\n","创建包含其他图层的类似图层的东西时使用的主类是tf.keras.Model。实现一个是通过继承自tf.keras.Model完成的。"]},{"cell_type":"code","metadata":{"id":"C2RqlBARZyje","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":226},"outputId":"d15b35e8-d023-433f-90fc-e92caf84705b","executionInfo":{"status":"ok","timestamp":1566734177425,"user_tz":-480,"elapsed":4084,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["class ResnetIdentityBlock(tf.keras.Model):\n","  def __init__(self, kernel_size, filters):\n","    super(ResnetIdentityBlock, self).__init__(name='')\n","    filters1, filters2, filters3 = filters\n","    \n","    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n","    self.bn2a = tf.keras.layers.BatchNormalization()\n","    \n","    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n","    self.bn2b = tf.keras.layers.BatchNormalization()\n","    \n","    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n","    self.bn2c = tf.keras.layers.BatchNormalization()\n","    \n","  def call(self, input_tensor, training=False):\n","    x = self.conv2a(input_tensor)\n","    x = self.bn2a(x, training=training)\n","    x = tf.nn.relu(x)\n","    \n","    x = self.conv2b(x)\n","    x = self.bn2b(x, training=training)\n","    x = tf.nn.relu(x)\n","    \n","    x = self.conv2c(x)\n","    x = self.bn2c(x, training=training)\n","    \n","    x += input_tensor\n","    return tf.nn.relu(x)\n","  \n","block = ResnetIdentityBlock(1, [1,2,3])\n","print(block(tf.zeros([1,2,3,3])))\n","print([x.name for x in block.trainable_variables])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["tf.Tensor(\n","[[[[0. 0. 0.]\n","   [0. 0. 0.]\n","   [0. 0. 0.]]\n","\n","  [[0. 0. 0.]\n","   [0. 0. 0.]\n","   [0. 0. 0.]]]], shape=(1, 2, 3, 3), dtype=float32)\n","['resnet_identity_block/conv2d/kernel:0', 'resnet_identity_block/conv2d/bias:0', 'resnet_identity_block/batch_normalization/gamma:0', 'resnet_identity_block/batch_normalization/beta:0', 'resnet_identity_block/conv2d_1/kernel:0', 'resnet_identity_block/conv2d_1/bias:0', 'resnet_identity_block/batch_normalization_1/gamma:0', 'resnet_identity_block/batch_normalization_1/beta:0', 'resnet_identity_block/conv2d_2/kernel:0', 'resnet_identity_block/conv2d_2/bias:0', 'resnet_identity_block/batch_normalization_2/gamma:0', 'resnet_identity_block/batch_normalization_2/beta:0']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8cMIIV8OovJY","colab_type":"text"},"source":["然而，在很多时候，组成许多层的模型只是将一层接一层地称为一层。这可以使用`tf.keras.Sequential`在非常少的代码中完成"]},{"cell_type":"code","metadata":{"id":"KsjbpKMpokRH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":185},"outputId":"a9dfccd6-fa2d-41f4-e019-badbcc350383","executionInfo":{"status":"ok","timestamp":1566734463310,"user_tz":-480,"elapsed":1417,"user":{"displayName":"方明旺","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDnQeY1Sj3TbOfbHRabw-tZJn02nI0_dgYYjVYb=s64","userId":"06059548827349409826"}}},"source":["my_seq = tf.keras.Sequential([\n","    tf.keras.layers.Conv2D(1,(1,1)),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Conv2D(2,1,padding='same'),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Conv2D(3, (1,1)),\n","    tf.keras.layers.BatchNormalization()\n","])\n","\n","my_seq(tf.zeros([1,2,3,3]))"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: id=514, shape=(1, 2, 3, 3), dtype=float32, numpy=\n","array([[[[0., 0., 0.],\n","         [0., 0., 0.],\n","         [0., 0., 0.]],\n","\n","        [[0., 0., 0.],\n","         [0., 0., 0.],\n","         [0., 0., 0.]]]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"ir_vAJ6aqiNf","colab_type":"text"},"source":["##下一步\n","现在，您可以返回到之前的笔记本并调整线性回归示例，以使用更好的结构化图层和模型。"]},{"cell_type":"code","metadata":{"id":"eNLjXDJkpquC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}