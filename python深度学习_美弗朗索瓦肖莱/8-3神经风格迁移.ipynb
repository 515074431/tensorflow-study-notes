{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8-3神经风格迁移.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9T2o17i15lDG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"outputId":"8ba8f012-cb76-4b93-dbbe-6fe774b62a5d","executionInfo":{"status":"ok","timestamp":1565921326703,"user_tz":-480,"elapsed":91239,"user":{"displayName":"方明旺","photoUrl":"https://lh4.googleusercontent.com/-mkhlHsh5fvw/AAAAAAAAAAI/AAAAAAAAAAA/uZC5ERYFZ4k/s64/photo.jpg","userId":"06059548827349409826"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jwMGq00oBrkA","colab_type":"code","colab":{}},"source":["!mkdir deep_style_turn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lXzvR-mE6lu2","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"/content/drive/My Drive/data/deep_style_turn\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lANhpfgHL5yZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"cc246a45-45ef-4a5c-dc78-354404323dc9","executionInfo":{"status":"ok","timestamp":1565921363388,"user_tz":-480,"elapsed":4994,"user":{"displayName":"方明旺","photoUrl":"https://lh4.googleusercontent.com/-mkhlHsh5fvw/AAAAAAAAAAI/AAAAAAAAAAA/uZC5ERYFZ4k/s64/photo.jpg","userId":"06059548827349409826"}}},"source":["!pwd"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/data/deep_style_turn\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jzwFiO7pi-wn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":215},"outputId":"23368d6b-124a-4438-af11-e768fe9b63b4","executionInfo":{"status":"ok","timestamp":1565932575103,"user_tz":-480,"elapsed":4291,"user":{"displayName":"方明旺","photoUrl":"https://lh4.googleusercontent.com/-mkhlHsh5fvw/AAAAAAAAAAI/AAAAAAAAAAA/uZC5ERYFZ4k/s64/photo.jpg","userId":"06059548827349409826"}}},"source":["!wget http://n.sinaimg.cn/collect/crawl/20160224/j0or-fxprucs6463696.jpg"],"execution_count":25,"outputs":[{"output_type":"stream","text":["--2019-08-16 05:16:13--  http://n.sinaimg.cn/collect/crawl/20160224/j0or-fxprucs6463696.jpg\n","Resolving n.sinaimg.cn (n.sinaimg.cn)... 2.21.41.13, 2a02:26f0:7b:481::102d, 2a02:26f0:7b:48a::102d\n","Connecting to n.sinaimg.cn (n.sinaimg.cn)|2.21.41.13|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 58368 (57K) [image/jpeg]\n","Saving to: ‘j0or-fxprucs6463696.jpg’\n","\n","\rj0or-fxprucs6463696   0%[                    ]       0  --.-KB/s               \rj0or-fxprucs6463696 100%[===================>]  57.00K  --.-KB/s    in 0.003s  \n","\n","2019-08-16 05:16:13 (21.5 MB/s) - ‘j0or-fxprucs6463696.jpg’ saved [58368/58368]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iw00779k4M49","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"e2adc089-d303-437b-dd82-ec9122543dbf","executionInfo":{"status":"ok","timestamp":1565921463301,"user_tz":-480,"elapsed":3541,"user":{"displayName":"方明旺","photoUrl":"https://lh4.googleusercontent.com/-mkhlHsh5fvw/AAAAAAAAAAI/AAAAAAAAAAA/uZC5ERYFZ4k/s64/photo.jpg","userId":"06059548827349409826"}}},"source":["from keras.preprocessing.image import load_img, img_to_array\n","\n","target_image_path = 'portrait.jpg' #想要变换的图像的路径\n","style_reference_image_path = 'transfer_style_reference.jpg' #风格图像的路径\n","\n","#生成图像的尺寸\n","width, height = load_img(target_image_path).size\n","img_height = 400\n","img_width = int(width * img_height / height)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Y5B6aL9QMWd-","colab_type":"text"},"source":["- 辅助函数"]},{"cell_type":"code","metadata":{"id":"FyEmLxxhMT30","colab_type":"code","colab":{}},"source":["import numpy as np\n","from keras.applications import vgg19"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HJBXRiRhMliT","colab_type":"code","colab":{}},"source":["def preprocess_image(image_path):\n","  img = load_img(image_path, target_size=(img_height, img_width))\n","  img = img_to_array(img)\n","  img = np.expand_dims(img, axis=0)\n","  img = vgg19.preprocess_input(img)\n","  return img\n","\n","def deprocess_image(x):\n","  #vgg19.preprocess_input 的作用是减去ImageNet 的平均像素值，\n","  #使其中心为0。这里相当于vgg19.preprocess_input 的逆操作\n","  x[:,:,0] += 103.939\n","  x[:,:,1] += 116.779\n","  x[:,:,2] += 123.68\n","  #将图像由BGR 格式转换为RGB 格式。这也是vgg19.preprocess_input 逆操作的一部分\n","  x = x[:,:,::-1]\n","  \n","  x = np.clip(x,0,255).astype('uint8')\n","  return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4cfnqQP7O9r3","colab_type":"text"},"source":["下面构建VGG19 网络。它接收三张图像的批量作为输入，三张图像分别是风格参考图像、\n","目标图像和一个用于保存生成图像的占位符。占位符是一个符号张量，它的值由外部Numpy 张\n","量提供。风格参考图像和目标图像都是不变的，因此使用K.constant 来定义，但生成图像的\n","占位符所包含的值会随着时间而改变。\n","\n","-  加载预训练的VGG19 网络，并将其应用于三张图像"]},{"cell_type":"code","metadata":{"id":"p63xk_phN5eE","colab_type":"code","colab":{}},"source":["from keras import backend as K"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FBk0OyfsPGPH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":325},"outputId":"3b39c8e3-1e25-4612-eb45-300c4621a81d","executionInfo":{"status":"ok","timestamp":1565922722949,"user_tz":-480,"elapsed":9181,"user":{"displayName":"方明旺","photoUrl":"https://lh4.googleusercontent.com/-mkhlHsh5fvw/AAAAAAAAAAI/AAAAAAAAAAA/uZC5ERYFZ4k/s64/photo.jpg","userId":"06059548827349409826"}}},"source":["target_image = K.constant(preprocess_image(target_image_path))\n","style_reference_image = K.constant(preprocess_image(style_reference_image_path))\n","#这个占位符用于保存生成图像\n","combination_image = K.placeholder((1,img_height,img_width,3))\n","\n","#将三张图像合并为一个批量\n","input_tensor = K.concatenate([target_image,\n","                             style_reference_image,\n","                             combination_image],\n","                            axis=0)\n","\n","#利用三张图像组成的批量作为输入\n","#来构建VGG19 网络。加载模型将\n","#使用预训练的ImageNet 权重\n","model = vgg19.VGG19(input_tensor=input_tensor,\n","                   weights='imagenet',\n","                   include_top=False)\n","print('Model loaded.')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0816 02:31:55.201576 140092940949376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0816 02:31:55.208717 140092940949376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0816 02:31:55.210487 140092940949376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0816 02:31:55.251318 140092940949376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80142336/80134624 [==============================] - 3s 0us/step\n"],"name":"stdout"},{"output_type":"stream","text":["W0816 02:31:59.449075 140092940949376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","W0816 02:31:59.450181 140092940949376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Model loaded.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"z62KOm6GRRRm","colab_type":"text"},"source":["我们来定义内容损失，它要保证目标图像和生成图像在VGG19 卷积神经网络的顶层具有相\n","似的结果。\n","\n","- 内容损失"]},{"cell_type":"code","metadata":{"id":"_j09p4X-Qt_X","colab_type":"code","colab":{}},"source":["def content_loss(base, combination):\n","  return K.sum(K.square(combination - base))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SHQG9ABoR62e","colab_type":"text"},"source":["接下来是风格损失。它使用一个辅助函数来计算输入矩阵的格拉姆矩阵，即原始特征矩阵\n","中相互关系的映射。\n","- 风格损失"]},{"cell_type":"code","metadata":{"id":"Zs5oEK-YR5v4","colab_type":"code","colab":{}},"source":["def gram_matrix(x):\n","  features = K.batch_flatten(K.permute_dimensions(x,(2,0,1)))\n","  gram = K.dot(features, K.transpose(features))\n","  return gram\n","\n","def style_loss(style, combination):\n","  S = gram_matrix(style)\n","  C = gram_matrix(combination)\n","  channels = 3\n","  size = img_height * img_width\n","  return K.sum(K.square(S - C )) / (4. * (channels ** 2) * (size ** 2 ))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_9ZpznuJTOwg","colab_type":"text"},"source":["除了这两个损失分量，我们还要添加第三个——总变差损失（total variation loss），它对生成\n","的组合图像的像素进行操作。它促使生成图像具有空间连续性，从而避免结果过度像素化。你\n","可以将其理解为正则化损失。\n","\n","- 总变差损失"]},{"cell_type":"code","metadata":{"id":"byHeSwAuTNVq","colab_type":"code","colab":{}},"source":["def total_variation_loss(x):\n","  a = K.square(x[:, :img_height -1, :img_width -1, :] -\n","              x[:, 1:, :img_width -1, :])\n","  b = K.square(x[:, :img_height -1, :img_width -1, :] -\n","             x[:, :img_height -1, 1:, :])\n","  return K.sum(K.pow(a + b, 1.25))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qFYyv6K-UYR0","colab_type":"text"},"source":["我们需要最小化的损失是这三项损失的加权平均。为了计算内容损失，我们只使用一个靠\n","顶部的层，即block5_conv2 层；而对于风格损失，我们需要使用一系列层，既包括顶层也包\n","括底层。最后还需要添加总变差损失。\n","根据所使用的风格参考图像和内容图像，很可能还需要调节content_weight 系数（内容\n","损失对总损失的贡献比例）。更大的content_weight 表示目标内容更容易在生成图像中被识\n","别出来。\n","\n","- 定义需要最小化的最终损失"]},{"cell_type":"code","metadata":{"id":"9JryefSHUNo9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"d2530ae0-ddd8-4fd1-d56e-a812330222d9","executionInfo":{"status":"ok","timestamp":1565924478633,"user_tz":-480,"elapsed":1128,"user":{"displayName":"方明旺","photoUrl":"https://lh4.googleusercontent.com/-mkhlHsh5fvw/AAAAAAAAAAI/AAAAAAAAAAA/uZC5ERYFZ4k/s64/photo.jpg","userId":"06059548827349409826"}}},"source":["#将层的名称映射为激活张量的字典\n","outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n","#用于内容损失的层\n","content_layer = 'block5_conv2'\n","#用于风格损失的层\n","style_layers = ['block1_conv1',\n","               'block2_conv1',\n","               'block3_conv1',\n","               'block4_conv1',\n","               'block5_conv1']\n","\n","#损失分量的加权平均所使用的权重\n","total_variation_weight = 1e-4\n","style_weight = 1.\n","content_weight = 0.025\n","\n","#添加内容损失\n","loss = K.variable(0.) #在定义损失时将所有分量添加到这个标量变量中\n","layer_features = outputs_dict[content_layer]\n","target_image_features = layer_features[0, :, :, :]\n","combination_features = layer_features[2, :, :, :]\n","loss += content_weight * content_loss(target_image_features, combination_features)\n","\n","\n","#添加每个目标层的风格损失分量\n","for layer_name in style_layers:\n","  layer_features = outputs_dict[layer_name]\n","  style_reference_features = layer_features[1, :, :, :]\n","  combination_features = layer_features[2, :, :, :]\n","  sl = style_loss(style_reference_features, combination_features)\n","  loss += (style_weight / len(style_layers)) * sl\n","  \n","#添加总变差损失  \n","loss += total_variation_weight * total_variation_loss(combination_image)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["W0816 03:01:18.469416 140092940949376 variables.py:2429] Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"ZK6ow7A7YSjE","colab_type":"text"},"source":["最后需要设置梯度下降过程。在Gatys 等人最初的论文中，使用L-BFGS 算法进行最优化，\n","所以我们这里也将使用这种方法。这是本例与8.2 节DeepDream 例子的主要区别。L-BFGS 算\n","法内置于SciPy 中，但SciPy 实现有两个小小的限制。\n","\n","-  它需要将损失函数值和梯度值作为两个单独的函数传入。\n","-  它只能应用于展平的向量，而我们的数据是三维图像数组。\n","\n","分别计算损失函数值和梯度值是很低效的，因为这么做会导致二者之间大量的冗余计算。\n","这一过程需要的时间几乎是联合计算二者所需时间的2 倍。为了避免这种情况，我们将创建一\n","个名为Evaluator 的Python 类，它可以同时计算损失值和梯度值，在第一次调用时会返回损\n","失值，同时缓存梯度值用于下一次调用。\n","\n","- 设置梯度下降过程"]},{"cell_type":"code","metadata":{"id":"n1cpHbhOX0nq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":91},"outputId":"6664eceb-a69e-45da-9847-0168fe250e14","executionInfo":{"status":"ok","timestamp":1565925338439,"user_tz":-480,"elapsed":969,"user":{"displayName":"方明旺","photoUrl":"https://lh4.googleusercontent.com/-mkhlHsh5fvw/AAAAAAAAAAI/AAAAAAAAAAA/uZC5ERYFZ4k/s64/photo.jpg","userId":"06059548827349409826"}}},"source":["grads = K.gradients(loss, combination_image)[0] #获取损失相对于生成图像的梯度\n","\n","#用于获取当前损失值和当前梯度值的函数\n","fetch_loss_and_grads = K.function([combination_image],[loss,grads])\n","\n","class Evaluator(object):\n","  #这个类将fetch_loss_and_grads 包\n","  #装起来，让你可以利用两个单独的方法\n","  #调用来获取损失和梯度，这是我们要使\n","  #用的SciPy 优化器所要求的\n","  \n","  def __init__(self):\n","    self.loss_value = None\n","    self.grads_values = None\n","    \n","  def loss(self, x):\n","    assert self.loss_value is None\n","    x = x.reshape((1, img_height, img_width, 3))\n","    outs = fetch_loss_and_grads([x])\n","    loss_value = outs[0]\n","    grad_values = outs[1].flatten().astype('float64')\n","    self.loss_value = loss_value\n","    self.grad_values = grad_values\n","    return self.loss_value\n","  \n","  def grads(self, x):\n","    assert self.loss_value is not None\n","    grad_values = np.copy(self.grad_values)\n","    self.loss_value = None\n","    self.grad_values = None\n","    return grad_values\n","  \n","  \n","evaluator = Evaluator()\n","    "],"execution_count":18,"outputs":[{"output_type":"stream","text":["W0816 03:15:38.448963 140092940949376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"aRvy43PVbNu7","colab_type":"text"},"source":["最后，可以使用SciPy 的L-BFGS 算法来运行梯度上升过程，在算法每一次迭代时都保存\n","当前的生成图像（这里一次迭代表示20 个梯度上升步骤）。\n","\n","-  　风格迁移循环"]},{"cell_type":"code","metadata":{"id":"chWcvo4QbGkp","colab_type":"code","colab":{}},"source":["from scipy.optimize import fmin_l_bfgs_b\n","import imageio\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6plrmTGib024","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"8ab0739a-9ba7-4d2d-9634-13f0a6d79921","executionInfo":{"status":"ok","timestamp":1565934647850,"user_tz":-480,"elapsed":80153,"user":{"displayName":"方明旺","photoUrl":"https://lh4.googleusercontent.com/-mkhlHsh5fvw/AAAAAAAAAAI/AAAAAAAAAAA/uZC5ERYFZ4k/s64/photo.jpg","userId":"06059548827349409826"}}},"source":["localtime = time.localtime()\n","_,_,_,tm_hour,tm_min,*_ = localtime\n","result_prefix = 'my_result'\n","iterations = 20\n","\n","#这是初始状态：目标图像\n","x = preprocess_image(target_image_path)\n","#将图像展平，因为scipy.optimize.fmin_l_bfgs_b 只能处理展平的向量\n","x = x.flatten()\n","\n","for i in range(iterations):\n","  print('Start of iteration ', i)\n","  start_time = time.time()\n","  #对生成图像的像素运行\n","  #L-BFGS 最优化，以将神\n","  #经风格损失最小化。注意，\n","  #必须将计算损失的函数和\n","  #计算梯度的函数作为两个\n","  #单独的参数传入\n","  x, min_val, info = fmin_l_bfgs_b(evaluator.loss,\n","                                  x,\n","                                  fprime=evaluator.grads,\n","                                  maxfun=20)\n","  print('Current loss value:', min_val)\n","  \n","  #保存当前的生成图像\n","  img = x.copy().reshape((img_height, img_width, 3))\n","  img = deprocess_image(img)\n","  fname = result_prefix + '_at _iteration_%d_%d_%d.png' % (tm_hour,tm_min,i)\n","  imageio.imwrite(fname, img)\n","  print('Image saved as ',fname)\n","  end_time = time.time()\n","  print('Iteration %d completed in %ds' % (i, end_time - start_time))"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Start of iteration  0\n","Current loss value: 2047948800.0\n","Image saved as  my_result_at _iteration_5_49_0.png\n","Iteration 0 completed in 3s\n","Start of iteration  1\n","Current loss value: 1222187100.0\n","Image saved as  my_result_at _iteration_5_49_1.png\n","Iteration 1 completed in 3s\n","Start of iteration  2\n","Current loss value: 895021060.0\n","Image saved as  my_result_at _iteration_5_49_2.png\n","Iteration 2 completed in 3s\n","Start of iteration  3\n","Current loss value: 730217660.0\n","Image saved as  my_result_at _iteration_5_49_3.png\n","Iteration 3 completed in 3s\n","Start of iteration  4\n","Current loss value: 628251650.0\n","Image saved as  my_result_at _iteration_5_49_4.png\n","Iteration 4 completed in 3s\n","Start of iteration  5\n","Current loss value: 564356700.0\n","Image saved as  my_result_at _iteration_5_49_5.png\n","Iteration 5 completed in 3s\n","Start of iteration  6\n","Current loss value: 516258700.0\n","Image saved as  my_result_at _iteration_5_49_6.png\n","Iteration 6 completed in 3s\n","Start of iteration  7\n","Current loss value: 479371000.0\n","Image saved as  my_result_at _iteration_5_49_7.png\n","Iteration 7 completed in 3s\n","Start of iteration  8\n","Current loss value: 450614370.0\n","Image saved as  my_result_at _iteration_5_49_8.png\n","Iteration 8 completed in 3s\n","Start of iteration  9\n","Current loss value: 427185000.0\n","Image saved as  my_result_at _iteration_5_49_9.png\n","Iteration 9 completed in 3s\n","Start of iteration  10\n","Current loss value: 407482430.0\n","Image saved as  my_result_at _iteration_5_49_10.png\n","Iteration 10 completed in 3s\n","Start of iteration  11\n","Current loss value: 390372160.0\n","Image saved as  my_result_at _iteration_5_49_11.png\n","Iteration 11 completed in 3s\n","Start of iteration  12\n","Current loss value: 376042000.0\n","Image saved as  my_result_at _iteration_5_49_12.png\n","Iteration 12 completed in 3s\n","Start of iteration  13\n","Current loss value: 363514430.0\n","Image saved as  my_result_at _iteration_5_49_13.png\n","Iteration 13 completed in 3s\n","Start of iteration  14\n","Current loss value: 352002600.0\n","Image saved as  my_result_at _iteration_5_49_14.png\n","Iteration 14 completed in 3s\n","Start of iteration  15\n","Current loss value: 341708300.0\n","Image saved as  my_result_at _iteration_5_49_15.png\n","Iteration 15 completed in 3s\n","Start of iteration  16\n","Current loss value: 332575650.0\n","Image saved as  my_result_at _iteration_5_49_16.png\n","Iteration 16 completed in 3s\n","Start of iteration  17\n","Current loss value: 324085950.0\n","Image saved as  my_result_at _iteration_5_49_17.png\n","Iteration 17 completed in 3s\n","Start of iteration  18\n","Current loss value: 316237800.0\n","Image saved as  my_result_at _iteration_5_49_18.png\n","Iteration 18 completed in 3s\n","Start of iteration  19\n","Current loss value: 308771170.0\n","Image saved as  my_result_at _iteration_5_49_19.png\n","Iteration 19 completed in 3s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cPLFdTpxh6v8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}